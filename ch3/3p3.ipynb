{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Synthetic Regression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What will happen if the number of examples cannot be divided by the batch size. How would you change this behavior by specifying a different argument by using the framework’s API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.DataLoader() function has the `drop_last` arg. If set to True, it drops the last incomplete batch if the dataset size is not divisible by the batch size. If False and the size of the dataset is not divisible by the batch size, then the last batch will be smaller.\n",
    "\n",
    "By default, the `drop_last` arg is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Suppose that we want to generate a huge dataset, where both the size of the parameter vector w and the number of examples num_examples are large.\n",
    "\n",
    "1. What happens if we cannot hold all data in memory?\n",
    "\n",
    "2. How would you shuffle the data if it is held on disk? Your task is to design an efficient algorithm that does not require too many random reads or writes. Hint: [pseudorandom permutation generators](https://en.wikipedia.org/wiki/Pseudorandom_permutation) allow you to design a reshuffle without the need to store the permutation table explicitly (Naor and Reingold, 1999)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a data generator that produces new data on the fly, every time the iterator is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n",
      "torch.Size([32, 2]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class SyntheticRegressionData(d2l.DataModule):\n",
    "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
    "                 batch_size=32):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = torch.randn(n, len(w))\n",
    "        noise = torch.randn(n, 1) * noise\n",
    "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n",
    "    def get_dataloader(self, train):\n",
    "        if train:\n",
    "            indices = list(range(0, self.num_train))\n",
    "            # The examples are read in random order\n",
    "            random.shuffle(indices)\n",
    "        else:\n",
    "            indices = list(range(self.num_train, self.num_train+self.num_val))\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            batch_indices = torch.tensor(indices[i: i+self.batch_size])\n",
    "            yield self.X[batch_indices], self.y[batch_indices]\n",
    "\n",
    "data = SyntheticRegressionData(w=torch.tensor([2.0, 3.0]), b=0.5)\n",
    "cnt = 0\n",
    "for X, y in data.train_dataloader():\n",
    "    cnt += 1\n",
    "    print(X.shape, y.shape)\n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How would you design a random data generator that generates the same data each time it is called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的随机数算法在初始化阶段都需要一个随机种子(random seed), 完全相同的种子每次将产生相同的随机数序列。如果没有手动进行显式设置，系统则默认根据时间来选择这个值，此时每次生成的随机数因时间差异而不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.2177],\n",
      "        [-1.3179],\n",
      "        [-2.9639],\n",
      "        [ 5.3909],\n",
      "        [ 0.9725],\n",
      "        [ 4.1932],\n",
      "        [ 8.0397],\n",
      "        [-0.1258],\n",
      "        [ 6.1278],\n",
      "        [ 4.6633]])\n",
      "tensor([-0.0209])\n",
      "tensor([-0.7185])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "data1 = SyntheticRegressionData(w=torch.tensor([2.0, 3.0]), b=0.5, num_train=5, num_val=5)\n",
    "# data2 = SyntheticRegressionData(w=torch.tensor([2.0, 3.0]), b=0.5, num_train=5, num_val=5)\n",
    "print(data1.y)   # 第一次调用和第二次调用的结果不一致，原因是每次调用都生成了新的随机数，导致结果不一致。\n",
    "# print(data2.y) # 但同一个位置的语句再次运行生成的结果是一样的.\n",
    "print(torch.randn(1))\n",
    "print(torch.randn(1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
